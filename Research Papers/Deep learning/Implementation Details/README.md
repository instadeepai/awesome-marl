### Implementation

<details> <summary> <a href="https://arxiv.org/pdf/2005.12729.pdf"> IMPLEMENTATION MATTERS IN DEEP POLICY GRADIENTS: A CASE STUDY ON PPO AND TRPO </a>by Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Firdaus Janoos, Larry Rudolph, and Aleksander Madry. ICLR 2020 <a href="https://www.Summary.so/instadeep/Multiagent-Learning-Basics-Challenges-and-Prospect-21cb7b4294b84a4188cafd184a3deed8">   </a> </summary>  TODO: add abstract <br> - </details>

<details> <summary> <a href="https://arxiv.org/pdf/2103.01955.pdf"> The Surprising Effectiveness of PPO in Cooperative Multi-Agent Games </a>by Chao Yu,Akash Velu, Eugene Vinitsky, Yu Wang, Alexandre Bayen. arXiv 2021 <a href="https://www.Summary.so/instadeep/Multiagent-Learning-Basics-Challenges-and-Prospect-21cb7b4294b84a4188cafd184a3deed8">   </a> </summary>  TODO: add abstract <br> - </details>

<details> <summary> <a href="https://arxiv.org/pdf/2102.03479.pdf"> RETHINKING THE IMPLEMENTATION TRICKS AND MONOTONICITY CONSTRAINT IN COOPERATIVE MULTI-AGENT REINFORCEMENT LEARNING </a>by Jian Hu, Siyang Jiang, Seth Austin Harding, Haibin Wu and Shih-wei Liao. arXiv 2022 <a href="https://github.com/instadeepai/awesome-marl/blob/main/Research%20Papers/Deep%20learning/RETHINKING%20THE%20IMPLEMENTATION%20TRICKS%20AND%20MONOTONICITY%20CONSTRAINT%20IN%20COOPERATIVE%20MULTI-AGENT%20REINFORCEMENT%20LEARNING.md"> [Summary] </a> </summary>  Many complex multi-agent systems such as robot swarms control and autonomous vehicle coordination can be modeled as Multi-Agent Reinforcement Learning (MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge (SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX target relaxing the monotonicity constraint of QMIX, allowing for performance improvement in SMAC. In this paper, we investigate the code-level optimizations of these variants and the monotonicity constraint. (1) We find that such improvements of the variants are significantly affected by various code-level optimizations. (2) The experiment results show that QMIX with normalized optimizations outperforms other works in SMAC; (3) beyond the common wisdom from these works, the monotonicity constraint can improve sample efficiency in SMAC and DEPP. We also discuss why monotonicity constraints work well in purely cooperative tasks with a theoretical analysis. We open-source the code at https://github.com/hijkzzz/pymarl2. <br> - </details>

<details> <summary> <a href="https://arxiv.org/abs/2203.05285"> API: Boosting Multi-Agent Reinforcement Learning via Agent-Permutation-Invariant Networks </a>by Xiaotian Hao, Weixun Wang, Hangyu Mao, Yaodong Yang, Dong Li, Yan Zheng, Zhen Wang and Jianye Hao. arXiv 2022 <a href="https://www.Summary.so/instadeep/Multiagent-Learning-Basics-Challenges-and-Prospect-21cb7b4294b84a4188cafd184a3deed8">   </a> </summary>  TODO: add abstract <br> - </details>